{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jelenalazovic/Desktop/5/IP2/env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jelenalazovic/Desktop/5/IP2/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('srpski.csv', sep='\\t')\n",
    "df = df.drop(columns=['Rbr', 'SR', 'sr/sr', 'Naslov', 'Jezik'])\n",
    "\n",
    "df['label'] = df['Autor'].astype('category').cat.codes\n",
    "df = df.drop(columns=['Autor'])\n",
    "df = df.rename(columns={'Tekst':'text'})\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 718/718 [00:00<00:00, 373kB/s]\n",
      ".gitattributes: 100%|██████████| 345/345 [00:00<00:00, 694kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 583kB/s]\n",
      "README.md: 100%|██████████| 3.78k/3.78k [00:00<00:00, 8.83MB/s]\n",
      "config.json: 100%|██████████| 718/718 [00:00<00:00, 762kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 153kB/s]\n",
      "pytorch_model.bin:  70%|██████▉   | 776M/1.11G [11:29<02:44, 2.04MB/s] Error while downloading from https://cdn-lfs.huggingface.co/sentence-transformers/paraphrase-xlm-r-multilingual-v1/224f40dde228eb17d15e7d26caa90f35806def427cd2e48e6f892fb62d64c6fb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1708290261&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODI5MDI2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9zZW50ZW5jZS10cmFuc2Zvcm1lcnMvcGFyYXBocmFzZS14bG0tci1tdWx0aWxpbmd1YWwtdjEvMjI0ZjQwZGRlMjI4ZWIxN2QxNWU3ZDI2Y2FhOTBmMzU4MDZkZWY0MjdjZDJlNDhlNmY4OTJmYjYyZDY0YzZmYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=AGb4HVihVh-5xIbCFdBUTvI40VnE3lmlNiPdfljbgzVS1HoHLjMpwfeSQ4BW2KREYRLT%7EPZ2-8pPaAwDDp6cEESTsf%7E7x4h69WHo90OyjtSoDk01DqaErW%7ErxF-RZQ%7ECGIBzFOv8UDUbDYMJ0QUED7C7V5mywENvTBNzAivbdjSHzAppOHQclbnegA0akhP5E1IojvWP2pLSK9xEpRA24Vn20eXGISBMxx3CdFnpZptm-FN73MOio-TVIeVQu5SrWbunldXsPpXyxQGU8ojaxpb5yBlLP8cYBaQiRDrronypSFpaAk5%7EaTgpqw%7EQzbvIG7TuzVFRZbFCyYl3D5%7EoVg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "pytorch_model.bin: 100%|██████████| 1.11G/1.11G [03:29<00:00, 1.60MB/s]\n",
      "pytorch_model.bin:  70%|██████▉   | 776M/1.11G [15:15<06:36, 848kB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 24.3kB/s]\n",
      "sentencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:04<00:00, 1.22MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 150/150 [00:00<00:00, 62.3kB/s]\n",
      "tokenizer.json: 100%|██████████| 9.10M/9.10M [00:06<00:00, 1.37MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 550/550 [00:00<00:00, 258kB/s]\n",
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 112kB/s]\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'sentence-transformers/paraphrase-xlm-r-multilingual-v1' \n",
    "model = SetFitModel.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    num_iterations=20,\n",
    "    column_mapping={'text':\"text\", \"label\": \"label\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search_function(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [4, 8, 16, 32])    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n",
      "Generating Training Pairs: 100%|██████████| 20/20 [00:00<00:00, 52.25it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 4400\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 275\n",
      "  Total train batch size = 16\n",
      "Iteration: 100%|██████████| 275/275 [41:44<00:00,  9.11s/it]\n",
      "Epoch: 100%|██████████| 1/1 [41:44<00:00, 2504.30s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to evaluation dataset\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.2857142857142857}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fed891f0f39c693a1b845aefd197cf9be2347fa8ca49a7dc47460742f6cfbc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
