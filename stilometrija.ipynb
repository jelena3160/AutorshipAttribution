{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('srpski.csv', sep='\\t')\n",
    "df = df.drop(columns=['Rbr', 'SR', 'sr/sr', 'Naslov', 'Jezik'])\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = df[column].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizacija reci i recenica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktLanguageVars\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangVars(PunktLanguageVars):\n",
    "    sent_end_chars = ('.', '!', '?', ';', \":\", \"...\", '..','…')\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(lang_vars=LangVars())\n",
    "df['Recenice'] = df['Tekst'].apply(custom_sent_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tokenizer = RegexpTokenizer(r'\\w+[\\'\\’]*\\w*|[^\\w\\s]')\n",
    "df['Tokeni'] = df['Tekst'].apply(custom_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = r'[^\\w\\s]'\n",
    "def remove_punctuation(tokens): \n",
    "    filtered_tokens = [word for word in tokens if not re.match(punctuation, word)]\n",
    "    return filtered_tokens\n",
    "\n",
    "df['Filtrirani tokeni'] = df['Tokeni'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for words in df['Filtrirani tokeni'] for word in words]\n",
    "fdist = FreqDist(all_words)\n",
    "stopwords = [word for word, count in fdist.items() if count > 50 or (len(word) in (1,2,3) and count > 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords]\n",
    "    return filtered_tokens\n",
    "\n",
    "#df['Filtrirani tokeni'] = df['Filtrirani tokeni'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stilometrija_medjukorak.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podela podataka na trening i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Tekst', 'Recenice', 'Tokeni','Filtrirani tokeni']]\n",
    "y = df['Autor']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stilometrijske analize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(words):\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "df_train['Duzina reci'] = df_train['Filtrirani tokeni'].apply(average_word_length)\n",
    "df_test['Duzina reci'] = df_test['Filtrirani tokeni'].apply(average_word_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgWordLength = df_train.groupby('Autor')['Duzina reci'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_avgWordLength['Autor'], df_avgWordLength['Duzina reci'])\n",
    "plt.xlabel('Autor')\n",
    "plt.ylabel('Dužina reči')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_length(sentences):\n",
    "    return sum(len(sentence.split()) for sentence in sentences) / len(sentences)\n",
    "\n",
    "df_train['Duzina recenica'] = df_train['Recenice'].apply(average_sentence_length)\n",
    "df_test['Duzina recenica'] = df_test['Recenice'].apply(average_sentence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgSentLength = df_train.groupby('Autor')['Duzina recenica'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_avgSentLength['Autor'], df_avgSentLength['Duzina recenica'], color='cyan')\n",
    "plt.xlabel('Autor')\n",
    "plt.ylabel('Dužina rečenice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_length(words):\n",
    "    return sum(len(word) for word in words)\n",
    "df_train['Duzina teksta'] = df_train['Tokeni'].apply(text_length)\n",
    "df_test['Duzina teksta'] = df_test['Tokeni'].apply(text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avgTextLength = df_train.groupby('Autor')['Duzina teksta'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_avgTextLength['Autor'], df_avgTextLength['Duzina teksta'], color='orange')\n",
    "plt.xlabel('Autor')\n",
    "plt.ylabel('Dužina teksta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "model = RandomForestClassifier(max_depth=5, min_samples_split=15, n_estimators=300)\n",
    "\n",
    "model.fit(df_train[['Duzina reci', 'Duzina recenica', 'Duzina teksta']], df_train['Autor'])\n",
    "\n",
    "y_train_pred_rf = model.predict(df_train[['Duzina reci', 'Duzina recenica', 'Duzina teksta']])\n",
    "\n",
    "# Predikcije na test skup\n",
    "y_test_pred_rf = model.predict(df_test[['Duzina reci', 'Duzina recenica', 'Duzina teksta']])\n",
    "\n",
    "print('Random Forest - Trening skup:\\n')\n",
    "print(f'Tačnost: {accuracy_score(df_train[\"Autor\"], y_train_pred_rf)}')\n",
    "print(f'F1 ocena: {f1_score(df_train[\"Autor\"], y_train_pred_rf, average=\"weighted\")}')\n",
    "print(f'Odziv: {recall_score(df_train[\"Autor\"], y_train_pred_rf, average=\"weighted\")}\\n')\n",
    "\n",
    "print('Random Forest - Test skup:\\n')\n",
    "print(f'Tačnost: {accuracy_score(df_test[\"Autor\"], y_test_pred_rf)}')\n",
    "print(f'F1 ocena: {f1_score(df_test[\"Autor\"], y_test_pred_rf, average=\"weighted\")}')\n",
    "print(f'Odziv: {recall_score(df_test[\"Autor\"], y_test_pred_rf, average=\"weighted\")}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifierMB = MultinomialNB()\n",
    "\n",
    "# Treniranje modela na trening skupu\n",
    "classifierMB.fit(df_train[['Duzina reci', 'Duzina recenica', 'Duzina teksta']], df_train['Autor'])\n",
    "\n",
    "# Predikcije na trening skupu\n",
    "y_train_pred_MB = classifierMB.predict(df_train[['Duzina reci', 'Duzina recenica', 'Duzina teksta']])\n",
    "\n",
    "# Predikcije na test skupu\n",
    "y_test_pred_MB = classifierMB.predict(df_test[['Duzina reci', 'Duzina recenica', 'Duzina teksta']])\n",
    "\n",
    "# Evaluacione metrike za Multinomial Bajes\n",
    "print('Multinomial Bajes - Trening skup:\\n')\n",
    "print(f'Tačnost: {accuracy_score(df_train[\"Autor\"], y_train_pred_MB)}')\n",
    "print(f'F1 ocena: {f1_score(df_train[\"Autor\"], y_train_pred_MB, average=\"weighted\")}')\n",
    "print(f'Odziv: {recall_score(df_train[\"Autor\"], y_train_pred_MB, average=\"weighted\")}\\n')\n",
    "\n",
    "print('Multinomial Bajes - Test skup:\\n')\n",
    "print(f'Tačnost: {accuracy_score(df_test[\"Autor\"], y_test_pred_MB)}')\n",
    "print(f'F1 ocena: {f1_score(df_test[\"Autor\"], y_test_pred_MB, average=\"weighted\")}')\n",
    "print(f'Odziv: {recall_score(df_test[\"Autor\"], y_test_pred_MB, average=\"weighted\")}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
